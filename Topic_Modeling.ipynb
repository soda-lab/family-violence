{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import sqlite3\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtz = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(word):\n",
    "    if word.startswith('#'):\n",
    "        return word\n",
    "    \n",
    "    lemma = lmtz.lemmatize(word, 'v')\n",
    "    if lemma == word:\n",
    "        lemma = lmtz.lemmatize(word, 'n')\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def strip_punc(s):\n",
    "    if s[0] == '#' or s[0] == '@':\n",
    "        return s\n",
    "    return ''.join([c for c in s if c.isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [strip_punc(w) for w in stopwords.words('english')]\n",
    "stop_words.extend([\n",
    "    'i',\n",
    "    'u',\n",
    "    'r',\n",
    "    'im',\n",
    "    'cant',\n",
    "    'would',\n",
    "    'family',\n",
    "    'domestic',\n",
    "    'violence',\n",
    "    'australia',\n",
    "    'australian',\n",
    "    'dv',\n",
    "    'fv',\n",
    "    'wa',\n",
    "    'via',\n",
    "    'today',\n",
    "    'thing',\n",
    "    'make',\n",
    "    'talk',\n",
    "    'due',\n",
    "    'day',\n",
    "    'month',\n",
    "    'find',\n",
    "    'show',\n",
    "    'put',\n",
    "    'part',\n",
    "    'time',\n",
    "    'yeah',\n",
    "    'deal',\n",
    "    'big',\n",
    "    'level',\n",
    "    'focus',\n",
    "    'theyre',\n",
    "    'list',\n",
    "    'top',\n",
    "    'give',\n",
    "    'situation',\n",
    "    'lot',\n",
    "    'hold',\n",
    "    'number',\n",
    "    'include',\n",
    "    'form',\n",
    "    'back',\n",
    "    'involve',\n",
    "    'link',\n",
    "    'real'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26039"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('dpc.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "year = 2016\n",
    "\n",
    "data = []\n",
    "replied_ids = []\n",
    "for (date, text, ftext, replied_id) in c.execute('SELECT created_at, text, [extended_tweet.full_text], in_reply_to_status_id FROM tweets'):\n",
    "    if date.split(' ')[-1] == str(year):\n",
    "        if ftext:\n",
    "            data.append(ftext)\n",
    "        else:\n",
    "            data.append(text)\n",
    "        \n",
    "        if replied_id:\n",
    "            replied_ids.append(replied_id)\n",
    "        else:\n",
    "            replied_ids.append(None)\n",
    "        \n",
    "conn.close()\n",
    "print(len(data))\n",
    "len(replied_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 "
     ]
    }
   ],
   "source": [
    "set_cleaned_sent = set()\n",
    "data_lemmatized = []\n",
    "data_filtered = []\n",
    "indices = [] # points back to index in original data\n",
    "\n",
    "for i, sent in enumerate(data):\n",
    "    \n",
    "    cleaned_sent = ''\n",
    "    for token in sent.split():\n",
    "        \n",
    "        # Cleaning\n",
    "        if token[0] in ['@','$','%','^','&','*'] or token.startswith('http'):\n",
    "            continue\n",
    "\n",
    "        # Remove puctuations, lower case\n",
    "        token = strip_punc(token.lower())\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemma = lemmatize(token)\n",
    "\n",
    "        if lemma and lemma not in stop_words:\n",
    "            cleaned_sent += lemma + ' '\n",
    "    \n",
    "    cleaned_sent = cleaned_sent.strip()\n",
    "    \n",
    "    # Check for duplicates\n",
    "    if cleaned_sent and cleaned_sent not in set_cleaned_sent:\n",
    "        set_cleaned_sent.add(cleaned_sent)\n",
    "        data_lemmatized.append(cleaned_sent.split())\n",
    "        data_filtered.append(sent)\n",
    "        indices.append(i)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(data_lemmatized[:50]):\n",
    "    print(indices[i], sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bigram and Trigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_lemmatized, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_lemmatized], threshold=100)  \n",
    "\n",
    "# Faster way to get a Tweet clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = make_bigrams(data_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['say']]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LDA Mallet Model\n",
    "Malletâ€™s version of LDA often gives a better quality of topics.\n",
    "Num of topics = 20 at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
    "# ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=12, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal number of topics for LDA\n",
    "Build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        print(str(len(model_list)-1)+'-'+str(num_topics),end=' ')\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic coherence provide a convenient measure to judge how good a given topic model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-8 1-9 2-10 "
     ]
    }
   ],
   "source": [
    "# Takes a long time to run.\n",
    "start = 8\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=8, limit=11, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_list[0]\n",
    "\n",
    "#from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative document for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the dominant topic in each Tweet\n",
    "\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus=corpus, texts=data_filtered):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=model, corpus=corpus, texts=data_filtered)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute dominant topic for each Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 40 Tweets under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_dominant_topic.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Topic_Perc_Contrib'], ascending=[0]).head(10)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Format\n",
    "# sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "len(sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "#topic_names = ['Action needed','Legal action',\"Men's actions\",'Advocacy & campaigning','Government action','Violence justified','Service','Abuse experiences','Social causes','Culture of Violence']\n",
    "# 2015\n",
    "#topic_names = ['Culture & attitudes','Government action','Services needed',\"Men's actions\",'Advocacy & campaigning','Policing','Prevalence']\n",
    "#2016\n",
    "#topic_names = ['Violence & policing','Male perpetrators','Government inaction','Community support','Law reform','Successful programs','Social determinants',\"Victims' Experiences\"]\n",
    "#2017\n",
    "#topic_names = ['Social context','Male perpetrators','Survival and Inspiration','Prevalence & risk','Programs & services','Men as victims']\n",
    "#2018\n",
    "#topic_names = ['Gun violence','Prevalence',\"Men's actions\",'Contexts & causes','Prevention Strategy','Government inaction','Abuse experiences','Advocacy & Campaigning','Politics & Governance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Key','Doc_Id'])\n",
    "\n",
    "for i, row in sent_topics_sorteddf_mallet.iterrows():\n",
    "        topic_i = int(row['Dominant_Topic'])\n",
    "        df.loc[i] = [str(year)+topic_names[topic_i], indices[row['Document_No']]]\n",
    "\n",
    "df.to_csv('output/topic_tweets/{}_topic_tweets.csv'.format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(i1, i2):\n",
    "    vectors = model.get_topics()\n",
    "    return 1 - cosine(vectors[i1], vectors[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/topic_sim/2018.csv', 'w') as f:\n",
    "    f.write('Topic,And_Topic,Similarity\\n')\n",
    "    for i1 in range(start-1):\n",
    "        for i2 in range(i1+1, start):\n",
    "            f.write('{},{},{}\\n'.format(i1+1, i2+1, get_sim(i1,i2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "for i1 in range(start-1):\n",
    "    for i2 in range(i1+1, start):\n",
    "        G.add_edge(i1, i2, weight=get_sim(i1,i2)*100)\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "edges = G.edges()\n",
    "weights = [G[u][v]['weight'] for u,v in edges]\n",
    "\n",
    "labels = {}\n",
    "for i in range(start):\n",
    "    labels[i] = str(i)\n",
    "\n",
    "color = '#E74C3C'\n",
    "nx.draw_networkx_nodes(G,pos,node_color=color,node_size=2000)\n",
    "nx.draw_networkx_labels(G,pos,labels,font_size=16)\n",
    "nx.draw(G, pos, edges=edges, width=weights, node_color=color, edge_color='grey')\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('2017')\n",
    "plt.savefig(\"output/topic_sim/2017.png\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sim(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=11; start=8; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.figure().suptitle('2018')\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the 3 optimal models\n",
    "optimal_model = model_list[0]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show\n",
    "x=0\n",
    "for text in df_dominant_topic[df_dominant_topic['Dominant_Topic']==5.0]['Text']:\n",
    "    print(text, '\\n')\n",
    "    x+=1\n",
    "    if x>30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 2 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "counts2 = {}\n",
    "for text in sent_topics_sorteddf_mallet[(sent_topics_sorteddf_mallet['Dominant_Topic']==2.0) | (sent_topics_sorteddf_mallet['Dominant_Topic']==5.0)]['Text']:\n",
    "    for token in text.strip().split():\n",
    "        if token.startswith('#'):\n",
    "            tag = strip_punc(token).lower()\n",
    "            counts[tag] = counts.get(tag,0)+1\n",
    "        if token.startswith('@'):\n",
    "            tag = strip_punc(token).lower()\n",
    "            counts2[tag] = counts2.get(tag,0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tag in list(reversed(sorted(counts, key=counts.get)))[:30]:\n",
    "    print(tag+':', counts[tag])\n",
    "print()\n",
    "for tag in list(reversed(sorted(counts2, key=counts2.get)))[:30]:\n",
    "    print(tag+':', counts2[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top handlers for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'abcnews':'ABC News',\n",
    "    'whiteribbonaust':'White Ribbon',\n",
    "    'qanda': 'ABC Q&A',\n",
    "    'thetodayshow':'The Today Show',\n",
    "    'theage':'The Age',\n",
    "    'acurrentaffair':'A Current Affair (marketplace)',\n",
    "    'theprojecttv':'The Project (news)',\n",
    "    'dvvic':'DV Vic',\n",
    "    'smh':'Sydney Morning Herald',\n",
    "    'dv':'Demostic Violence',\n",
    "    'buzzrothfield':'Phil Rothfield (sports journalist)',\n",
    "    'tonyabbottmhr': 'Tony Abbott',\n",
    "    'charliepick':'Charlie Pickering (host)',\n",
    "    'danielandrewsmp': 'Dan Andrews (MP)',\n",
    "    'rosiebatty': 'Rosie Batty',\n",
    "    'billshortenmp': 'Bill Shorten',\n",
    "    'corybernardi':'Cory Bernardi (conservative)',\n",
    "    'mariska': 'Mariska Hargitay (actress)',\n",
    "    'mikebairdmp': 'Mike Baird (politician)',\n",
    "    'colleenhartland': 'Colleen Hartland (MP)',\n",
    "    'changeaus': 'Change.org',\n",
    "    'dailylifeau': 'Daily Life',\n",
    "    'conversationedu': 'The Conversation (news analysis)',\n",
    "    'familycourtau':'Family Court',\n",
    "    'womensagenda':\"Women's Agenda (news)\",\n",
    "    'turnbullmalcolm': 'Malcolm Turnbull',\n",
    "    'annastaciamp': 'Annastacia Palaszczuk (MP)',\n",
    "    'johnmcaldwell': 'John Caldwell (reporter)',\n",
    "    'lizbroderick':'Elizabeth Broderick (activist)',\n",
    "    'frichardsonmp': 'Fiona Richardson (MP)',\n",
    "    'erin': 'Erin Caton (activist)',\n",
    "    'vanbadham': 'Van Badham (commentator)',\n",
    "    'kate': 'Kate (artist)',\n",
    "    'carringtonkl': 'Kerry Carrington (professor)',\n",
    "    'skinnergj':\"Dougy's Daily Digest\",\n",
    "    'newscomauhq':'news.com.au',\n",
    "    'youtube': 'Youtube',\n",
    "    'bairdjulia':'Dr Julia Baird (journalist)',\n",
    "    'paulinehansonoz':'Pauline Hanson (politician)',\n",
    "    'lyleshelton':'Lyle Shelton (lobbyist)',\n",
    "    'mirandadevine':'Miranda Devine (columnist)',\n",
    "    'senatorcash':'Michaelia Cash (minister)',\n",
    "    'skynewsaust':'Sky News',\n",
    "    'nrl':'National Rugby League',\n",
    "    'ourwatchaus':'Our Watch',\n",
    "    'realmarklatham':'Mark Latham (politician)',\n",
    "    'nathutchins':'Natalie Hutchins (politician)',\n",
    "    'peterdutton':'Peter Dutton (MP)',\n",
    "    'perkinsmiki':'Miki Perkins (editor)',\n",
    "    'canberratimes':'Canberra Times',\n",
    "    'dancingceo': 'Dancing CEO (lifestyle)',\n",
    "    'scottmorrisonmp': 'Scott Morrison',\n",
    "    'hpu': \"Hawaii Pacific Univ.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler_counts_each_topic = [{},{},{},{},{},{},{},{}]\n",
    "for _, row in sent_topics_sorteddf_mallet.iterrows():\n",
    "    topic_idx = int(row['Dominant_Topic'])\n",
    "    dic = handler_counts_each_topic[topic_idx]\n",
    "    text = data[indices[int(row['Document_No'])]]\n",
    "\n",
    "    for token in text.split(' '):\n",
    "        if token.startswith('@'):\n",
    "            token += '/'\n",
    "            i = 1\n",
    "            while token[i].isalpha():\n",
    "                i += 1\n",
    "            if i > 1:\n",
    "                handler = token[0:i].lower()\n",
    "                dic[handler] = dic.get(handler, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(handler_counts_each_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencers_df = pd.read_csv('middle-data/influencers-5.csv')\n",
    "influencers_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "influencers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "x = 2016\n",
    "table.append(['topic_idx','influencer_idx','count','topic','influencer'])\n",
    "df = influencers_df[influencers_df['year']==x]\n",
    "for i in range(8):\n",
    "    for ii, row in df.iterrows():\n",
    "        if row['handler'] in handler_counts_each_topic[i]:\n",
    "            count = handler_counts_each_topic[i][row['handler']]\n",
    "            table.append([i, 9-ii+(x-2014)*10, count, topic_names[i], row['name']])\n",
    "            \n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table[1:], columns=table[0]).to_csv('output/topic_influencer/2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most dominant topics and number of documents for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "series_topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "idx = []\n",
    "topic_counts = []\n",
    "keywords = []\n",
    "topic_contributions = []\n",
    "\n",
    "for (i, count) in series_topic_counts.iteritems():\n",
    "    idx.append(int(i))\n",
    "    keywords.append(\", \".join([word for word, _ in optimal_model.show_topic(int(i))]))\n",
    "    topic_counts.append(count)\n",
    "    topic_contributions.append(str(round(100*count/series_topic_counts.sum(), 2))+'%')\n",
    "    \n",
    "df_dominant_topics = pd.DataFrame.from_dict({\n",
    "    'Dominant_Topic_Num': idx,\n",
    "    'Topic_Keywords': keywords, \n",
    "    'Num_Documents': topic_counts, \n",
    "    'Perc_Documents': topic_contributions\n",
    "})\n",
    "\n",
    "# Show\n",
    "pd.options.display.max_colwidth = 100\n",
    "df_dominant_topics.set_index('Dominant_Topic_Num', inplace=True)\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "\n",
    "writer = ExcelWriter('output/2014/data/2014_13_clusters.xlsx')\n",
    "new_df = df_dominant_topics.copy()\n",
    "new_df.index += 1\n",
    "new_df.to_excel(writer,'topic_rank')\n",
    "\n",
    "for topic_no in range(13):\n",
    "    new_df = sent_topics_sorteddf_mallet.iloc[topic_no*40:((topic_no+1)*40),[0,4]]\n",
    "    new_df.set_index('Document_No', inplace=True)\n",
    "    \n",
    "    replied_texts = []\n",
    "    for i, row in new_df.iterrows():\n",
    "        if replied_ids[indices[i]]:\n",
    "            try:\n",
    "                text = api.get_status(replied_ids[indices[i]], tweet_mode='extended').full_text\n",
    "                replied_texts.append(text)\n",
    "            except:\n",
    "                replied_texts.append('')\n",
    "        else:\n",
    "            replied_texts.append('')\n",
    "            \n",
    "    new_df['In_Reply_To'] = replied_texts\n",
    "    \n",
    "    new_df.reset_index(inplace=True)\n",
    "    new_df.drop(['Document_No'], axis=1, inplace=True)\n",
    "    new_df.to_excel(writer,'topic_'+str(topic_no+1))\n",
    "    \n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model_list[0])\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'output/2014/visually_aided_clusters/2014_13_clusters.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [strip_punc(w) for w in stopwords.words('english')]\n",
    "stop_words.extend([\n",
    "    'i',\n",
    "    'u',\n",
    "    'r',\n",
    "    'im',\n",
    "    'cant',\n",
    "    'would',\n",
    "    'family',\n",
    "    'domestic',\n",
    "    'violence',\n",
    "    'australia',\n",
    "    'australian',\n",
    "    'dv',\n",
    "    'fv',\n",
    "    'au',\n",
    "    'via',\n",
    "    'today',\n",
    "    'thing',\n",
    "    'make',\n",
    "    'talk',\n",
    "    'due',\n",
    "    'day',\n",
    "    'month',\n",
    "    'find',\n",
    "    'show',\n",
    "    'put',\n",
    "    'part',\n",
    "    'time',\n",
    "    'yeah',\n",
    "    'deal',\n",
    "    'big',\n",
    "    'level',\n",
    "    'focus',\n",
    "    'theyre',\n",
    "    'list',\n",
    "    'top',\n",
    "    'give',\n",
    "    'situation',\n",
    "    'lot',\n",
    "    'hold',\n",
    "    'number',\n",
    "    'include',\n",
    "    'form',\n",
    "    'back',\n",
    "    'involve',\n",
    "    'link',\n",
    "    'real',\n",
    "    'get',\n",
    "    'go',\n",
    "    'have',\n",
    "    'do',\n",
    "    'take',\n",
    "    'time','year','month','week','day','say'\n",
    "])\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = ''\n",
    "    for token in text.split():\n",
    "        \n",
    "        # Cleaning\n",
    "        if token[0] in ['@','$','%','^','&','*'] or token.startswith('http'):\n",
    "            continue\n",
    "\n",
    "        # Remove puctuations, lower case\n",
    "        token = strip_punc(token.lower())\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemma = lemmatize(token)\n",
    "\n",
    "        if lemma and lemma not in stop_words:\n",
    "            cleaned_text += lemma + ' '\n",
    "    \n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "raw_docs = []\n",
    "conn = sqlite3.connect('dpc.db')\n",
    "\n",
    "df = pd.read_sql('SELECT text, [extended_tweet.full_text] FROM tweets', conn)\n",
    "conn.close()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = ''\n",
    "    if row['extended_tweet.full_text']:\n",
    "        text = clean_text(row['extended_tweet.full_text'])\n",
    "        raw_docs.append(row['extended_tweet.full_text'])\n",
    "    else:\n",
    "        text = clean_text(row['text'])\n",
    "        raw_docs.append(row['text'])\n",
    "    docs.append(text)\n",
    "\n",
    "print(len(docs), docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "vector_space = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_docs = []\n",
    "victim_raw_docs = []\n",
    "for text in sent_topics_sorteddf_mallet[(sent_topics_sorteddf_mallet['Dominant_Topic']==2.0) | (sent_topics_sorteddf_mallet['Dominant_Topic']==5.0)]['Text']:\n",
    "    victim_docs.append(clean_text(text))\n",
    "    victim_raw_docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.transform(victim_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for vector in vectors:\n",
    "    scores.append(np.sum(vector))\n",
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(scores)\n",
    "indices = (-arr).argsort()[:40]\n",
    "print(scores[indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in indices:\n",
    "    print(victim_raw_docs[idx], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ''\n",
    "for text in sent_topics_sorteddf_mallet[(sent_topics_sorteddf_mallet['Dominant_Topic']==2.0) | (sent_topics_sorteddf_mallet['Dominant_Topic']==5.0)]['Text']:\n",
    "    doc += clean_text(text) + ' '\n",
    "doc = doc.strip()    \n",
    "\n",
    "df = pd.DataFrame(vectorizer.transform([doc]).T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "print(df.sort_values(by=[\"tfidf\"],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "x = 0\n",
    "for text in victim_docs:\n",
    "    tokens = text.split()\n",
    "    for i in range(len(tokens)-1):\n",
    "        scores[(tokens[i], tokens[i+1])] = scores.get((tokens[i], tokens[i+1]),0)+1\n",
    "\n",
    "#     x += 1\n",
    "#     if x % 100 == 0:\n",
    "#         print(x, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in list(sorted(scores, key=scores.get, reverse=True))[:40]:\n",
    "    print(str(w)+':', scores[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(victim_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('dpc.db')\n",
    "\n",
    "df = pd.read_sql('SELECT count(*) FROM tweets where created_at like \"%2017\"', conn)\n",
    "conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
